
#
#FileCatalog=# select dataset,dsttype,count(filename),sum(events) from datasets where dsttype='DST_CALOFITTING_run2pp' group by dataset,dsttype;
#     dataset     |        dsttype         | count  |     sum     
#-----------------+------------------------+--------+-------------
# ana451_2024p009 | DST_CALOFITTING_run2pp |  50343 |  4976087047
# ana446_2024p007 | DST_CALOFITTING_run2pp | 148286 | 14632177735
#(2 rows)


# ----------------------------------------------------------------------------------------------------------------------------------------------
# Disable the DST_TRIGGERED_EVENT rule
DST_TRIGGERED_EVENT_run3auau:
   params:
     name:       DST_TRIGGERED_EVENT_$(streamname)_run3auau
     build:      ana.484
     build_name: ana484
     dbtag:      nocdbtag
     version :   1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   run_parallel.sh
     payload :   ./ProdFlow/run3auau/TriggerProduction/
     mem     :   2048M
     neventsper: 100000
     noverflow:   20000
     mnrun    : 57287
     mxrun    : 63758
     rsync  : "ProdFlow/run3auau/TriggerProduction/*"


   import_tables:
     - runselection:
         db: daq
         query: |-
           with runselection as (
           select run.*,hostinfo.hostname from run join hostinfo on run.runnumber=hostinfo.runnumber
           where
              run.runnumber>={mnrun}
              and
              run.runnumber<={mxrun}
              and
              runtype in ( 'cosmics', 'physics', 'beam' )
              and
              hostname != 'gl1daq'
              and
              hostname like '%seb%'
           )
           select runnumber, string_agg(hostname,',' order by hostname) as hosts from runselection group by runnumber
           
   input:
      db: raw
      lfn2pfn: lfn2lfn
      query: |-
        with config as (
        select {mnrun} as firstrun,
        {mxrun} as lastrun
        ),
        alldatasets as (
        select * from datasets,config where runnumber in ( select runnumber from runselection )
        ),
        allfiles as (
        select alldatasets.*,files.* from alldatasets join files on files.lfn=alldatasets.filename
        ),
        allstreams as (
        select runnumber,
        filename as streamfile,
        daqhost as streamname,
        full_host_name,
        dataset as runtype
        from allfiles    
        where
        daqhost in ( 'seb00','seb01','seb02','seb03','seb04','seb05',
        'seb06','seb07','seb08','seb09','seb10','seb11',
        'seb12','seb13','seb14','seb15','seb16','seb17',
        'seb18','seb19','seb20' )          
        and
        full_host_name='lustre'
        ),
        allgl1 as (
        select runnumber,
        filename as streamfile,
        --upper( daqhost ) as streamname,
        daqhost as streamname,
        full_host_name,
        dataset as runtype        
        from allfiles     
        where
        daqhost='gl1daq' 
        and
        full_host_name='lustre'
        ),
        alljobs1 as (
        select 'rawdata' as source,
        runnumber,
        0 as segment,
        string_agg( distinct streamfile, ' ' ) as files,
        'na' as fileranges,
        streamname,
        runtype
        from allstreams
        group by runnumber,allstreams.streamname,runtype
        ),
        alljobs2 as (
        select 'rawdata' as source,
        runnumber,
        0 as segment,
        string_agg( distinct streamfile, ' ' ) as gl1files,
        'na' as gl1fileranges
        from allgl1
        group by runnumber,allgl1.streamname,runtype
        ),
        alljobs as (
        select alljobs1.source,
        alljobs1.runnumber,
        alljobs1.segment,
        files||' '||gl1files as files,
        alljobs1.fileranges, 
        alljobs1.streamname,
        alljobs1.runtype
        from alljobs1 join alljobs2 on alljobs1.runnumber=alljobs2.runnumber
        )
        select * from alljobs


   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync} $(firstevent)"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority              : '3900'
     request_xferslots     : '1'

#   periodicremove        : '(JobStatus==2)&&(time()-EnteredCurrentStatus)>(3*24*3600)'

DST_TRIGGERED_EVENT_run3cosmics:
   params:
     name:       DST_TRIGGERED_EVENT_$(streamname)_run3cosmics
     build:      ana.484
     build_name: ana484
     dbtag:      nocdbtag
     version :   1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   run_parallel.sh
     payload :   ./ProdFlow/run3auau/TriggerProduction/
     mem     :   2048M
     neventsper: 100000
     noverflow:   20000
     mnrun: 57287
     mxrun: 63758
     rsync  : "ProdFlow/run3auau/TriggerProduction/*"


   import_tables:
     - runselection:
         db: daq
         query: |-
           with runselection as (
           select run.*,hostinfo.hostname from run join hostinfo on run.runnumber=hostinfo.runnumber
           where
              run.runnumber>={mnrun}
              and
              run.runnumber<={mxrun}
              and
              runtype in ( 'cosmics', 'physics', 'beam' )
              and
              hostname != 'gl1daq'
              and
              hostname like '%seb%'
           )
           select runnumber, string_agg(hostname,',' order by hostname) as hosts from runselection group by runnumber
           
   input:
      db: raw
      lfn2pfn: lfn2lfn
      query: |-
        with config as (
        select {mnrun} as firstrun,
        {mxrun} as lastrun
        ),
        alldatasets as (
        select * from datasets,config where runnumber in ( select runnumber from runselection )
        ),
        allfiles as (
        select alldatasets.*,files.* from alldatasets join files on files.lfn=alldatasets.filename
        ),
        allstreams as (
        select runnumber,
        filename as streamfile,
        daqhost as streamname,
        full_host_name,
        dataset as runtype
        from allfiles    
        where
        daqhost in ( 'seb00','seb01','seb02','seb03','seb04','seb05',
        'seb06','seb07','seb08','seb09','seb10','seb11',
        'seb12','seb13','seb14','seb15','seb16','seb17',
        'seb18','seb19','seb20' )          
        and
        full_host_name='lustre'
        ),
        allgl1 as (
        select runnumber,
        filename as streamfile,
        --upper( daqhost ) as streamname,
        daqhost as streamname,
        full_host_name,
        dataset as runtype        
        from allfiles     
        where
        daqhost='gl1daq' 
        and
        full_host_name='lustre'
        ),
        alljobs1 as (
        select 'rawdata' as source,
        runnumber,
        0 as segment,
        string_agg( distinct streamfile, ' ' ) as files,
        'na' as fileranges,
        streamname,
        runtype
        from allstreams
        group by runnumber,allstreams.streamname,runtype
        ),
        alljobs2 as (
        select 'rawdata' as source,
        runnumber,
        0 as segment,
        string_agg( distinct streamfile, ' ' ) as gl1files,
        'na' as gl1fileranges
        from allgl1
        group by runnumber,allgl1.streamname,runtype
        ),
        alljobs as (
        select alljobs1.source,
        alljobs1.runnumber,
        alljobs1.segment,
        files||' '||gl1files as files,
        alljobs1.fileranges, 
        alljobs1.streamname,
        alljobs1.runtype
        from alljobs1 join alljobs2 on alljobs1.runnumber=alljobs2.runnumber
        )
        select * from alljobs


   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync} $(firstevent)"     
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority              : '3900'
     request_xferslots     : '1'


# Downstream products fitting
DST_CALOFITTING_run3auau:
   params:
     name:       DST_CALOFITTING_run3auau
     nevents:    0
     build:      ana.484
     build_name: ana484
     dbtag:      2025p001
     version : 1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runy2fitting.sh
     payload :   ./ProdFlow/run3auau/CaloProduction/
     mem     :   1024MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/CaloProduction/*,cups.py"
     dstin  : 'DST_TRIGGERED_EVENT_%_run3auau'
     dataset : 'ana484_nocdbtag_v000'
     mnrun    : 57287
     mxrun    : 63758     

   import_tables:
     # Get the list of runs taken, and for each run, the list of daqhosts for the run... restricted to calorimeters
     - hosttable:
         db: daq
         query: |-
           select hostinfo.runnumber,string_agg(hostinfo.hostname,' ' order by hostname) as hosts,run.runtype from hostinfo join run on run.runnumber=hostinfo.runnumber where run.runnumber>={mnrun} and run.runnumber<={mxrun} and hostinfo.hostname like 'seb%' and runtype in ( 'physics', 'beam', 'cosmics' ) group by hostinfo.runnumber, run.runtype
           
     - runtable:
         db: daq
         query: |-           
           select runnumber as thisrun, runtype from run where runnumber>={mnrun} and runnumber<={mxrun} {run_condition} and runtype in ( 'cosmics', 'physics', 'beam' )

           
   input:
     db: filecatalog
     lfn2pfn: lfn2lfn
     query: |-
       with allruns as (
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                string_agg( distinct filename,' ')                      as files       ,
                'na'                                                    as fileranges  ,
                string_agg( split_part(filename,'_',4), ' ' order by filename ) as hosts

         from  
                datasets 
         where 

                dsttype like '{dstin}' and dataset='{dataset}'
              
                {run_condition}

         group by runnumber,segment
           
         {limit_condition}

         )

         select allruns.*,hosttable.runtype from allruns join hosttable on allruns.runnumber=hosttable.runnumber and allruns.hosts=hosttable.hosts         

         ;

         
   job:
     arguments             : "{nevents} {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority : '4000'


DST_CALOFITTING_run3cosmics:
   params:
     name:       DST_CALOFITTING_run3cosmics
     nevents:    0
     build:      ana.484
     build_name: ana484
     dbtag:      2025p001
     version : 1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runhcalcosmics.sh
     payload :   ./ProdFlow/run3auau/CaloProduction/
     mem     :   1024MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/CaloProduction/*"
     dstin  : 'DST_TRIGGERED_EVENT_%_run3cosmics'
     dataset : 'ana484_nocdbtag_v001'
     mnrun    : 57287
     mxrun    : 63758          

   import_tables:
     # Get the list of runs taken, and for each run, the list of daqhosts for the run... restricted to calorimeters
     - hosttable:
         db: daq
         query: |-
           select hostinfo.runnumber,string_agg(hostinfo.hostname,' ' order by hostname) as hosts,run.runtype from hostinfo join run on run.runnumber=hostinfo.runnumber where run.runnumber>={mnrun} and run.runnumber<={mxrun} and hostinfo.hostname like 'seb%' and runtype in ( 'physics', 'beam', 'cosmics' ) group by hostinfo.runnumber, run.runtype
           
     - runtable:
         db: daq
         query: |-           
           select runnumber as thisrun, runtype from run where runnumber>={mnrun} and runnumber<={mxrun} {run_condition} and runtype in ( 'cosmics', 'physics', 'beam' )

           
   input:
     db: filecatalog
     lfn2pfn: lfn2lfn
     query: |-
       with allruns as (
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                string_agg( distinct filename,' ')                      as files       ,
                'na'                                                    as fileranges  ,
                string_agg( split_part(filename,'_',4), ' ' order by filename ) as hosts

         from  
                datasets 
         where 

                dsttype like '{dstin}' and dataset='{dataset}'
              
                {run_condition}

         group by runnumber,segment
           
         {limit_condition}

         )

         select allruns.*,hosttable.runtype from allruns join hosttable on allruns.runnumber=hosttable.runnumber and allruns.hosts=hosttable.hosts         

         ;
   job:
     arguments             : "{nevents} {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority : '4000'

#_____________________________________________________________________________________________
DST_CALO_run3auau:
   params:
     name:       DST_CALO_run3auau
     build:      ana.484
     build_name: ana484
     dbtag:      2025p001
     version :   1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runy2calib.sh
     payload :   ./ProdFlow/run3auau/CaloProduction/
     mem     :   4096MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/CaloProduction/*"

   input:
     db: filecatalog
     query: |-
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                filename                                                as files       ,
                filename || ':' || 0 || ':' || events                   as fileranges 
         from  
                datasets
         where 
                dataset='ana484_2025p001_v000' and dsttype='DST_CALOFITTING_run3auau'
                {run_condition}

         {limit_condition}

         ;
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority : '4000'


# Downstream products
DST_JETS_run3auau:
   params:
     name:       DST_JETS_run3auau
     build:      ana.484
     build_name: ana484
     dbtag:      2025p001
     version : 1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runjets.sh
     payload :   ./ProdFlow/run3auau/JetProduction/
     mem     :   2096MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/JetProduction/*"

   input:
     db: filecatalog
     query: |-
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                filename                                                as files       ,
                'NA'                   as fileranges 
         from  
                datasets
         where 
                dsttype='DST_CALO_run3auau' and dataset='ana484_2025p001_v000'
                {run_condition}
           
         {limit_condition}

         ;
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority : '4000'




# Downstream products
DST_JETCALO_run3auau:
   params:
     name:       DST_JETCALO_run3auau
     build:      ana.484
     build_name: ana484
     dbtag:      2025p001
     version:    1
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runy2jetskim.sh
     payload :   ./ProdFlow/run3auau/JetProduction/
     mem     :   4096MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/JetProduction/*"

   input:
     db: filecatalog
     query: |-
         select
                'filecatalog/datasets'                                  as source      ,
                runnumber                                                              ,
                segment                                                                ,
                filename                                                as files       ,
                filename || ':' || 0 || ':' || events                   as fileranges
         from
                datasets
         where
                dataset='ana484_2025p001_v000' and dsttype='DST_CALOFITTING_run3auau'
                {run_condition}

         {limit_condition}

         ;
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     priority : '4000'
