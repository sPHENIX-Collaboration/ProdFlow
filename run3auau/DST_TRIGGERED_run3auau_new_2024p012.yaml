#
#FileCatalog=# select dataset,dsttype,count(filename),sum(events) from datasets where dsttype='DST_CALOFITTING_run2pp' group by dataset,dsttype;
#     dataset     |        dsttype         | count  |     sum     
#-----------------+------------------------+--------+-------------
# ana451_2024p009 | DST_CALOFITTING_run2pp |  50343 |  4976087047
# ana446_2024p007 | DST_CALOFITTING_run2pp | 148286 | 14632177735
#(2 rows)


# ----------------------------------------------------------------------------------------------------------------------------------------------
# Disable the DST_TRIGGERED_EVENT rule
DST_TRIGGERED_EVENT_run3auau:
   params:
     name:       DST_TRIGGERED_EVENT_run3auau
     build:      new
     build_name: new
     dbtag:      nocdbtag
     version :   0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   run.sh
     payload :   ./ProdFlow/run3auau/TriggerProduction/
     mem     :   2048M
     neventsper: 100000
     noverflow:   20000
     rsync  : "ProdFlow/run3auau/TriggerProduction/*,cups.py"


   #
   # input query:
   #
   # This builds a list of all runs known to the file catalog "datasets" table.
   # The query should return:
   # 1. The source of the information (formatted as database name/table name)
   # 2. The run number
   # 3. A sequence number (a placeholder fixed at zero for event builders)
   # 4. And a space-separated list of logical filenames 
   #
   # The {*_condition} parameters (run, seg, limit) are substituted by kaedama
   # based on (optional) command line options.
   #
   # For now, require GL1 files...
   #
   input:
      db: daqdb
      direct_path: /sphenix/lustre01/sphnxpro/physics/*/cosmics/
      query: |-
         with config as (
            select 
               {neventsper} as nevents,
               {noverflow} as noverflow
         ),

         fullevents as (
              select runnumber,max(lastevent)    as lastevent
              from filelist, config
              where (filename similar to '/bbox%/GL1_(beam|physics|cosmics)%.evt'        and lastevent>2 )

                 {run_condition} and runnumber>46000

              group by runnumber
              having
                     every(transferred_to_sdcc)   and
                     max(lastevent)>1000          and
                     sum( case when filename similar to '/bbox%/GL1_(beam|physics|cosmics)%' then 1 else 0 end )>0

              order by runnumber
         ),

         fulljobs as (
         select 
                'daqdb/filelist'                                                                                    as source      , 
                runnumber                                                                                                          , 
                0                                                                                                   as segment     , 
                string_agg( split_part(filename,'/',-1), ' ' order by filename)                                             as files       ,   
                string_agg( firstevent::text || ':' || lastevent::text || ':' || split_part(filename,'/',-1), ' ' order by filename )                    as fileranges  

         from  
                filelist,config
         where 
           ( 
             (filename  similar to '/bbox%/%emcal%(beam|physics|cosmics)%.prdf'    and lastevent>2 ) or 
             (filename  similar to '/bbox%/%HCal%(beam|physics|cosmics)%.prdf'     and lastevent>2 ) or
             (filename  similar to '/bbox%/%LL1%(beam|physics|cosmics)%.prdf'      and lastevent>2 ) or
             (filename  similar to '/bbox%/GL1_(beam|physics|cosmics)%.evt'       and lastevent>2 ) or
             (filename  similar to '/bbox%/%mbd%(beam|physics|cosmics)%.prdf'      and lastevent>2 ) or
             (filename  similar to '/bbox%/%ZDC%(beam|physics|cosmics)%.prdf'      and lastevent>2 ) 

           )

           {run_condition}

         group by runnumber

         having
                every(transferred_to_sdcc)   and
                max(lastevent)>1000          and
                sum( case when filename similar to '/bbox%/GL1_(beam|physics|cosmics)%' then 1 else 0 end )>0 and
                (
                   sum( case when filename similar to '/bbox%/%emcal%(beam|physics|cosmics)%'  then 1 else 0 end )>0 or
                   sum( case when filename similar to '/bbox%/%HCal%(beam|physics|cosmics)%'   then 1 else 0 end )>0 
                )

         order by runnumber
         ),

         fullrun as (

             select fulljobs.*,fullevents.lastevent from fulljobs join fullevents on fulljobs.runnumber=fullevents.runnumber

         ),

         unsegmented as ( 

             select *,'full run' as runtype from fullrun where true 
         ),

         segmented as (

            select source, 
                   runnumber,
                   generate_series(0,unsegmented.lastevent/config.nevents) as segment,
                   files,
                   fileranges,
                   lastevent,
                   nevents

             from unsegmented,config

         ),

         segmentedA as ( 

         select source,
                runnumber,
                segment,
                files,
                fileranges,
                lastevent, 
                segment*config.nevents as myfirstevent,
                least( (segment+1)*config.nevents - 1, lastevent ) as mylastevent,
                config.nevents 
 
                from segmented,config

          ),


          segmentedB as (

               select *,
                      mylastevent-myfirstevent as nprocessing,
                      lastevent-mylastevent-1  as nremaining from segmentedA,config  -- b/c we count from zero
       
          ),

          segmentedC as (


               select source, runnumber,
                      segment,
                      files,
                      fileranges,
                      myfirstevent,
                      (
                          select 
                             case
                                when nprocessing<config.noverflow  then -1
                                when nremaining>=config.nevents    then mylastevent
                                when nremaining>=config.noverflow  then mylastevent
                                when nremaining<config.noverflow   then lastevent
                                else                                    -2             -- unhandled, should be an error condition
                             end
                      ) as mylastevent,
                      lastevent,
                      nprocessing,
                      nremaining

                      from segmentedB,config

          )


          select 
               source,
                 runnumber,
                 segment,
                 files,
                 fileranges,
                 
                 (select count(*) from regexp_matches( files,      ' ', 'g' ))::integer =
                 (select count(*) from regexp_matches( fileranges, ' ', 'g' ))::integer as sanity,
                 myfirstevent as firstevent,
                 mylastevent  as lastevent,
                 lastevent    as runs_last_event

                 from segmentedC

          order by runnumber desc, segment;
                 
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync} $(firstevent) $(lastevent) $(runs_last_event) {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority              : '3900'
     request_xferslots     : '1'
     periodicremove        : '(JobStatus==2)&&(time()-EnteredCurrentStatus)>(3*24*3600)'

#cosmic event combining:
DST_TRIGGERED_EVENT_run3cosmics:
   params:
     name:       DST_TRIGGERED_EVENT_run3cosmics
     build:      new
     build_name: new
     dbtag:      nocdbtag
     version :   0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   run.sh
     payload :   ./ProdFlow/run3auau/TriggerProduction/
     mem     :   2048M
     neventsper: 100000
     noverflow:   20000
     rsync  : "ProdFlow/run3auau/TriggerProduction/*,cups.py"


   #
   # input query:
   #
   # This builds a list of all runs known to the file catalog "datasets" table.
   # The query should return:
   # 1. The source of the information (formatted as database name/table name)
   # 2. The run number
   # 3. A sequence number (a placeholder fixed at zero for event builders)
   # 4. And a space-separated list of logical filenames
   #
   # The {*_condition} parameters (run, seg, limit) are substituted by kaedama
   # based on (optional) command line options.
   #
   # For now, require GL1 files...
   #
   input:
      db: daqdb
      direct_path: /sphenix/lustre01/sphnxpro/physics/*/cosmics/
      query: |-
         with config as (
            select
               {neventsper} as nevents,
               {noverflow} as noverflow
         ),

         fullevents as (
              select runnumber,max(lastevent)    as lastevent
              from filelist, config
              where (filename similar to '/bbox%/GL1_(beam|physics|cosmics)%.evt'        and lastevent>2 )

                 {run_condition} and runnumber>46000

              group by runnumber
              having
                     every(transferred_to_sdcc)   and
                     max(lastevent)>1000          and
                     sum( case when filename similar to '/bbox%/GL1_(beam|physics|cosmics)%' then 1 else 0 end )>0

              order by runnumber
         ),

         fulljobs as (
         select
                'daqdb/filelist'                                                                                    as source      ,
                runnumber                                                                                                          ,
                0                                                                                                   as segment     ,
                string_agg( split_part(filename,'/',-1), ' ' order by filename)                                             as files       ,
                string_agg( firstevent::text || ':' || lastevent::text || ':' || split_part(filename,'/',-1), ' ' order by filename )                    as fileranges

         from
                filelist,config
         where
           (
             (filename  similar to '/bbox%/%emcal%(beam|physics|cosmics)%.prdf'    and lastevent>2 ) or
             (filename  similar to '/bbox%/%HCal%(beam|physics|cosmics)%.prdf'     and lastevent>2 ) or
             (filename  similar to '/bbox%/%LL1%(beam|physics|cosmics)%.prdf'      and lastevent>2 ) or
             (filename  similar to '/bbox%/GL1_(beam|physics|cosmics)%.evt'       and lastevent>2 ) or
             (filename  similar to '/bbox%/%mbd%(beam|physics|cosmics)%.prdf'      and lastevent>2 ) or
             (filename  similar to '/bbox%/%ZDC%(beam|physics|cosmics)%.prdf'      and lastevent>2 )

           )

           {run_condition}

         group by runnumber

         having
                every(transferred_to_sdcc)   and
                max(lastevent)>1000          and
                sum( case when filename similar to '/bbox%/GL1_(beam|physics|cosmics)%' then 1 else 0 end )>0 and
                (
                   sum( case when filename similar to '/bbox%/%emcal%(beam|physics|cosmics)%'  then 1 else 0 end )>0 or
                   sum( case when filename similar to '/bbox%/%HCal%(beam|physics|cosmics)%'   then 1 else 0 end )>0
                )

         order by runnumber
         ),

         fullrun as (

             select fulljobs.*,fullevents.lastevent from fulljobs join fullevents on fulljobs.runnumber=fullevents.runnumber

         ),

         unsegmented as (

             select *,'full run' as runtype from fullrun where true
         ),

         segmented as (

            select source,
                   runnumber,
                   generate_series(0,unsegmented.lastevent/config.nevents) as segment,
                   files,
                   fileranges,
                   lastevent,
                   nevents

             from unsegmented,config

         ),

         segmentedA as (

         select source,
                runnumber,
                segment,
                files,
                fileranges,
                lastevent,
                segment*config.nevents as myfirstevent,
                least( (segment+1)*config.nevents - 1, lastevent ) as mylastevent,
                config.nevents

                from segmented,config

          ),


          segmentedB as (

               select *,
                      mylastevent-myfirstevent as nprocessing,
                      lastevent-mylastevent-1  as nremaining from segmentedA,config  -- b/c we count from zero

          ),

          segmentedC as (


               select source, runnumber,
                      segment,
                      files,
                      fileranges,
                      myfirstevent,
                      (
                          select
                             case
                                when nprocessing<config.noverflow  then -1
                                when nremaining>=config.nevents    then mylastevent
                                when nremaining>=config.noverflow  then mylastevent
                                when nremaining<config.noverflow   then lastevent
                                else                                    -2             -- unhandled, should be an error condition
                             end
                      ) as mylastevent,
                      lastevent,
                      nprocessing,
                      nremaining

                      from segmentedB,config

          )


          select
               source,
                 runnumber,
                 segment,
                 files,
                 fileranges,

                 (select count(*) from regexp_matches( files,      ' ', 'g' ))::integer =
                 (select count(*) from regexp_matches( fileranges, ' ', 'g' ))::integer as sanity,
                 myfirstevent as firstevent,
                 mylastevent  as lastevent,
                 lastevent    as runs_last_event

                 from segmentedC

          order by runnumber desc, segment;

   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync} $(firstevent) $(la
stevent) $(runs_last_event) {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority              : '3900'
     request_xferslots     : '1'
     periodicremove        : '(JobStatus==2)&&(time()-EnteredCurrentStatus)>(3*24*3600)'


# Downstream products fitting
DST_CALOFITTING_run3auau:
   params:
     name:       DST_CALOFITTING_run3auau
     nevents:    0
     build:      new
     build_name: new
     dbtag:      2024p012
     version : 0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runy2fitting.sh
     payload :   ./ProdFlow/run3auau/CaloProduction/
     mem     :   1024MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/CaloProduction/*,cups.py"
     dstin  : 'DST_TRIGGERED_EVENT_run3auau'
     dataset : 'new_nocdbtag_v000'

   input:
     db: filecatalog
     query: |-
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                filename                                                as files       ,
                filename || ':' || 0 || ':' || events                   as fileranges 
         from  
                datasets
         where 

                dsttype='{dstin}' and dataset='{dataset}'
                
                {run_condition}
           
         {limit_condition}

         ;
   job:
     arguments             : "{nevents} {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority : '3900'




     
 # Downstream products for cosmics
DST_CALOFITTING_run3cosmics:
   params:
     name:       DST_CALOFITTING_run3cosmics
     nevents:    0
     build:      new
     build_name: new
     dbtag:      2024p012
     version : 0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runhcalcosmics.sh
     payload :   ./ProdFlow/run3auau/CaloProduction/
     mem     :   1024MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/CaloProduction/*,cups.py"
     dstin  : 'DST_TRIGGERED_EVENT_run3cosmics'
     dataset : 'new_nocdbtag_v000'

   input:
     db: filecatalog
     query: |-
         select
                'filecatalog/datasets'                                  as source      ,
                runnumber                                                              ,
                segment                                                                ,
                filename                                                as files       ,
                filename || ':' || 0 || ':' || events                   as fileranges
         from
                datasets
         where

                dsttype='{dstin}' and dataset='{dataset}'

                {run_condition}

         {limit_condition}

         ;
   job:
     arguments             : "{nevents} {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority : '3900'

#_____________________________________________________________________________________________
DST_CALO_run3auau:
   params:
     name:       DST_CALO_run3auau
     build:      new
     build_name: new
     dbtag:      2024p012
     version :   0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runy2calib.sh
     payload :   ./ProdFlow/run3auau/CaloProduction/
     mem     :   4096MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/CaloProduction/*"

   input:
     db: filecatalog
     query: |-
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                filename                                                as files       ,
                filename || ':' || 0 || ':' || events                   as fileranges 
         from  
                datasets
         where 
                dataset='new_2024p012_v000' and dsttype='DST_CALOFITTING_run3auau'
                {run_condition}

         {limit_condition}

         ;
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority : '3900'


# Downstream products
DST_JETS_run3auau:
   params:
     name:       DST_JETS_run3auau
     build:      new
     build_name: new
     dbtag:      2024p012
     version : 0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runjets.sh
     payload :   ./ProdFlow/run3auau/JetProduction/
     mem     :   2096MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/JetProduction/*"

   input:
     db: filecatalog
     query: |-
         select 
                'filecatalog/datasets'                                  as source      , 
                runnumber                                                              , 
                segment                                                                ,
                filename                                                as files       ,
                'NA'                   as fileranges 
         from  
                datasets
         where 
                dsttype='DST_CALO_run3auau' and dataset='new_2024p012_v000'
                {run_condition}
           
         {limit_condition}

         ;
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority : '3900'




# Downstream products
DST_JETCALO_run3auau:
   params:
     name:       DST_JETCALO_run3auau
     build:      new
     build_name: new
     dbtag:      2024p012
     version:    0
     logbase :   $(name)_$(build)_$(tag)_$(version)-$INT(run,{RUNFMT})-$INT(seg,{SEGFMT})
     outbase :   $(name)_$(build)_$(tag)_$(version)
     script  :   runy2jetskim.sh
     payload :   ./ProdFlow/run3auau/JetProduction/
     mem     :   4096MB
     neventsper: 50000
     rsync  : "./ProdFlow/run3auau/JetProduction/*"

   input:
     db: filecatalog
     query: |-
         select
                'filecatalog/datasets'                                  as source      ,
                runnumber                                                              ,
                segment                                                                ,
                filename                                                as files       ,
                filename || ':' || 0 || ':' || events                   as fileranges
         from
                datasets
         where
                dataset='new_2024p012_v000' and dsttype='DST_CALOFITTING_run3auau'
                {run_condition}

         {limit_condition}

         ;
   job:
     arguments             : "$(nevents) {outbase} {logbase} $(run) $(seg) $(outdir) $(buildarg) $(tag) $(inputs) $(ranges) {neventsper} {logdir} {histdir} {PWD} {rsync}"
     output_destination    : '{logdir}'
     log                   : '{condor}/{logbase}.condor'
     accounting_group      : "group_sphenix.mdc2"
     accounting_group_user : "sphnxpro"
     priority : '3900'
